{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to MongoDB collection\n",
    "client = pymongo.MongoClient()\n",
    "db = client.mashable\n",
    "collection = client.mashable.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull article content from MongoDB\n",
    "content = []\n",
    "for doc in collection.find({}, {'_id': 0, 'content': 1}):\n",
    "    content.append(doc['content'].encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check number of documents is equal to expected\n",
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define stop words to exclude from LDA topic modeling\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "content_no_punc = [\"\".join(char for char in text\n",
    "                           if char not in string.punctuation) \n",
    "                   for text in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove stopwords and tokenize\n",
    "documents = [[word.decode('utf-8')\n",
    "              for word in text.lower().split() \n",
    "              if word.decode('utf-8') not in stop] \n",
    "              for text in content_no_punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define lemmatizer\n",
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lemmatize vocabularly\n",
    "documents = [[lmtzr.lemmatize(token) for token in doc]\n",
    "              for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for doc in documents:\n",
    "     for token in doc:\n",
    "            frequency[token] += 1\n",
    "\n",
    "documents = [[token for token in doc if frequency[token] > 1]\n",
    "              for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "# store the dictionary, for future reference\n",
    "dictionary.save('mashable_LDA_dictionary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load dictionary\n",
    "dictionary = corpora.Dictionary.load('mashable_LDA_dictionary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create corpus for model\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store to disk, for later use\n",
    "corpora.MmCorpus.serialize('mashable_LDA_corpara.mm', corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load corpus\n",
    "corpus = corpora.MmCorpus('mashable_LDA_corpara.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train LDA model\n",
    "# alpha and eta are hyperparameters that affect sparsity of the \n",
    "# document-topic (theta) and topic-word (lambda) distributions. \n",
    "# Both default to a symmetric 1.0/num_topics prior. Setting to 'auto'\n",
    "# will learns an asymmetric prior directly from your data.\n",
    "\n",
    "lda = models.LdaModel(corpus,\n",
    "               id2word = dictionary,\n",
    "               alpha = 'auto',\n",
    "               eta = 'auto',\n",
    "               num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "lda.save('mashable.lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "lda = models.LdaModel.load('mashable.lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.018*2014 + 0.016*\\u2014 + 0.007*team + 0.005*music + 0.005*december + 0.004*ferguson + 0.004*world + 0.004*fan + 0.004*game + 0.004*one'),\n",
       " (1,\n",
       "  u'0.009*\\u2014 + 0.008*image + 0.008*also + 0.007*see + 0.006*video + 0.005*one + 0.005*like + 0.004*something + 0.004*time + 0.004*share'),\n",
       " (2,\n",
       "  u'0.011*\\u2014 + 0.008*people + 0.006*one + 0.006*like + 0.006*say + 0.005*time + 0.005*job + 0.005*work + 0.005*new + 0.005*get'),\n",
       " (3,\n",
       "  u'0.015*apple + 0.010*phone + 0.010*iphone + 0.008*device + 0.008*camera + 0.008*new + 0.007*\\u2014 + 0.007*screen + 0.007*also + 0.006*samsung'),\n",
       " (4,\n",
       "  u'0.008*also + 0.008*price + 0.008*device + 0.006*car + 0.005*\\u2014 + 0.005*one + 0.005*like + 0.004*make + 0.004*home + 0.004*get'),\n",
       " (5,\n",
       "  u'0.017*company + 0.009*year + 0.008*million + 0.007*also + 0.007*said + 0.006*apple + 0.006*new + 0.006*business + 0.006*\\u2014 + 0.005*share'),\n",
       " (6,\n",
       "  u'0.014*said + 0.010*police + 0.008*\\u2014 + 0.006*also + 0.006*government + 0.006*u + 0.006*officer + 0.005*state + 0.004*comment + 0.004*security'),\n",
       " (7,\n",
       "  u'0.009*said + 0.008*2014 + 0.007*\\u2014 + 0.005*also + 0.004*year + 0.004*city + 0.004*image + 0.004*people + 0.003*one + 0.003*new'),\n",
       " (8,\n",
       "  u'0.015*game + 0.006*film + 0.006*also + 0.006*one + 0.006*new + 0.006*\\u2014 + 0.005*story + 0.005*see + 0.005*movie + 0.005*show'),\n",
       " (9,\n",
       "  u'0.017*user + 0.015*app + 0.010*google + 0.010*also + 0.008*new + 0.007*apps + 0.007*facebook + 0.007*see + 0.006*io + 0.005*add')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test LDA feature generation\n",
    "test_doc = collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Having trouble finding something to watch on Amazon Instant Video? The retailer launched Monday an experimental browsing tool that lets users discover movies and TV shows based on their genre preferences or simply the mood they\\'re in. Movies and shows are divided up into categories, some of which bear the names of genres (i.e., \"Comedy\" and \"Mystery/Thriller\"), and others which are labeled by mood, such as \"Feel-Good\" and \"Exciting.\" Users can toggle between TV shows and movies, and apply filters to show only videos that are available for free viewing to Prime subscribers, or ones that bear G or PG ratings. It\\'s pretty basic, but it sure beats the haphazard organization of Amazon\\'s current Instant Video page, which mixes rows of new releases with bestsellers and personal recommendations. The move is the latest in a series of investment\\'s Amazon is making in its streaming video platform. Last week, the company inked a licensing agreement with A+E Networks to bring past seasons of shows from A&E, History, Lifetime and Bio to its streaming library \\xe2\\x80\\x94 shows, it should be noted, that Netflix subscribers lost access to in the fall. Amazon claims its streaming Prime catalog now numbers more than 33,000, double what it was a year ago. Screenshot courtesy of Amazon.com'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull content from Mongo Doc\n",
    "test_doc_content = test_doc['content'].encode('utf8')\n",
    "test_doc_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Having trouble finding something to watch on Amazon Instant Video The retailer launched Monday an experimental browsing tool that lets users discover movies and TV shows based on their genre preferences or simply the mood theyre in Movies and shows are divided up into categories some of which bear the names of genres ie Comedy and MysteryThriller and others which are labeled by mood such as FeelGood and Exciting Users can toggle between TV shows and movies and apply filters to show only videos that are available for free viewing to Prime subscribers or ones that bear G or PG ratings Its pretty basic but it sure beats the haphazard organization of Amazons current Instant Video page which mixes rows of new releases with bestsellers and personal recommendations The move is the latest in a series of investments Amazon is making in its streaming video platform Last week the company inked a licensing agreement with AE Networks to bring past seasons of shows from AE History Lifetime and Bio to its streaming library \\xe2\\x80\\x94 shows it should be noted that Netflix subscribers lost access to in the fall Amazon claims its streaming Prime catalog now numbers more than 33000 double what it was a year ago Screenshot courtesy of Amazoncom'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation\n",
    "test_doc_content = \"\".join(char for char \n",
    "                           in test_doc_content \n",
    "                           if char \n",
    "                           not in string.punctuation)\n",
    "test_doc_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'trouble',\n",
       " u'finding',\n",
       " u'something',\n",
       " u'watch',\n",
       " u'amazon',\n",
       " u'instant',\n",
       " u'video',\n",
       " u'retailer',\n",
       " u'launched',\n",
       " u'monday',\n",
       " u'experimental',\n",
       " u'browsing',\n",
       " u'tool',\n",
       " u'lets',\n",
       " u'users',\n",
       " u'discover',\n",
       " u'movies',\n",
       " u'tv',\n",
       " u'shows',\n",
       " u'based',\n",
       " u'genre',\n",
       " u'preferences',\n",
       " u'simply',\n",
       " u'mood',\n",
       " u'theyre',\n",
       " u'movies',\n",
       " u'shows',\n",
       " u'divided',\n",
       " u'categories',\n",
       " u'bear',\n",
       " u'names',\n",
       " u'genres',\n",
       " u'ie',\n",
       " u'comedy',\n",
       " u'mysterythriller',\n",
       " u'others',\n",
       " u'labeled',\n",
       " u'mood',\n",
       " u'feelgood',\n",
       " u'exciting',\n",
       " u'users',\n",
       " u'toggle',\n",
       " u'tv',\n",
       " u'shows',\n",
       " u'movies',\n",
       " u'apply',\n",
       " u'filters',\n",
       " u'show',\n",
       " u'videos',\n",
       " u'available',\n",
       " u'free',\n",
       " u'viewing',\n",
       " u'prime',\n",
       " u'subscribers',\n",
       " u'ones',\n",
       " u'bear',\n",
       " u'g',\n",
       " u'pg',\n",
       " u'ratings',\n",
       " u'pretty',\n",
       " u'basic',\n",
       " u'sure',\n",
       " u'beats',\n",
       " u'haphazard',\n",
       " u'organization',\n",
       " u'amazons',\n",
       " u'current',\n",
       " u'instant',\n",
       " u'video',\n",
       " u'page',\n",
       " u'mixes',\n",
       " u'rows',\n",
       " u'new',\n",
       " u'releases',\n",
       " u'bestsellers',\n",
       " u'personal',\n",
       " u'recommendations',\n",
       " u'move',\n",
       " u'latest',\n",
       " u'series',\n",
       " u'investments',\n",
       " u'amazon',\n",
       " u'making',\n",
       " u'streaming',\n",
       " u'video',\n",
       " u'platform',\n",
       " u'last',\n",
       " u'week',\n",
       " u'company',\n",
       " u'inked',\n",
       " u'licensing',\n",
       " u'agreement',\n",
       " u'ae',\n",
       " u'networks',\n",
       " u'bring',\n",
       " u'past',\n",
       " u'seasons',\n",
       " u'shows',\n",
       " u'ae',\n",
       " u'history',\n",
       " u'lifetime',\n",
       " u'bio',\n",
       " u'streaming',\n",
       " u'library',\n",
       " u'\\u2014',\n",
       " u'shows',\n",
       " u'noted',\n",
       " u'netflix',\n",
       " u'subscribers',\n",
       " u'lost',\n",
       " u'access',\n",
       " u'fall',\n",
       " u'amazon',\n",
       " u'claims',\n",
       " u'streaming',\n",
       " u'prime',\n",
       " u'catalog',\n",
       " u'numbers',\n",
       " u'33000',\n",
       " u'double',\n",
       " u'year',\n",
       " u'ago',\n",
       " u'screenshot',\n",
       " u'courtesy',\n",
       " u'amazoncom']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords and tokenize\n",
    "test_doc_content = [word.decode('utf-8')\n",
    "                    for word in test_doc_content.lower().split() \n",
    "                    if word.decode('utf-8') not in stop] \n",
    "test_doc_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'trouble',\n",
       " u'finding',\n",
       " u'something',\n",
       " u'watch',\n",
       " u'amazon',\n",
       " u'instant',\n",
       " u'video',\n",
       " u'retailer',\n",
       " u'launched',\n",
       " u'monday',\n",
       " u'experimental',\n",
       " u'browsing',\n",
       " u'tool',\n",
       " u'let',\n",
       " u'user',\n",
       " u'discover',\n",
       " u'movie',\n",
       " u'tv',\n",
       " u'show',\n",
       " u'based',\n",
       " u'genre',\n",
       " u'preference',\n",
       " u'simply',\n",
       " u'mood',\n",
       " u'theyre',\n",
       " u'movie',\n",
       " u'show',\n",
       " u'divided',\n",
       " u'category',\n",
       " u'bear',\n",
       " u'name',\n",
       " u'genre',\n",
       " u'ie',\n",
       " u'comedy',\n",
       " u'mysterythriller',\n",
       " u'others',\n",
       " u'labeled',\n",
       " u'mood',\n",
       " u'feelgood',\n",
       " u'exciting',\n",
       " u'user',\n",
       " u'toggle',\n",
       " u'tv',\n",
       " u'show',\n",
       " u'movie',\n",
       " u'apply',\n",
       " u'filter',\n",
       " u'show',\n",
       " u'video',\n",
       " u'available',\n",
       " u'free',\n",
       " u'viewing',\n",
       " u'prime',\n",
       " u'subscriber',\n",
       " u'one',\n",
       " u'bear',\n",
       " u'g',\n",
       " u'pg',\n",
       " u'rating',\n",
       " u'pretty',\n",
       " u'basic',\n",
       " u'sure',\n",
       " u'beat',\n",
       " u'haphazard',\n",
       " u'organization',\n",
       " u'amazon',\n",
       " u'current',\n",
       " u'instant',\n",
       " u'video',\n",
       " u'page',\n",
       " u'mix',\n",
       " u'row',\n",
       " u'new',\n",
       " u'release',\n",
       " u'bestseller',\n",
       " u'personal',\n",
       " u'recommendation',\n",
       " u'move',\n",
       " u'latest',\n",
       " u'series',\n",
       " u'investment',\n",
       " u'amazon',\n",
       " u'making',\n",
       " u'streaming',\n",
       " u'video',\n",
       " u'platform',\n",
       " u'last',\n",
       " u'week',\n",
       " u'company',\n",
       " u'inked',\n",
       " u'licensing',\n",
       " u'agreement',\n",
       " u'ae',\n",
       " u'network',\n",
       " u'bring',\n",
       " u'past',\n",
       " u'season',\n",
       " u'show',\n",
       " u'ae',\n",
       " u'history',\n",
       " u'lifetime',\n",
       " u'bio',\n",
       " u'streaming',\n",
       " u'library',\n",
       " u'\\u2014',\n",
       " u'show',\n",
       " u'noted',\n",
       " u'netflix',\n",
       " u'subscriber',\n",
       " u'lost',\n",
       " u'access',\n",
       " u'fall',\n",
       " u'amazon',\n",
       " u'claim',\n",
       " u'streaming',\n",
       " u'prime',\n",
       " u'catalog',\n",
       " u'number',\n",
       " u'33000',\n",
       " u'double',\n",
       " u'year',\n",
       " u'ago',\n",
       " u'screenshot',\n",
       " u'courtesy',\n",
       " u'amazoncom']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize vocabularly\n",
    "test_doc_content = [lmtzr.lemmatize(token) for token in test_doc_content]\n",
    "test_doc_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.050505202651516756),\n",
       " (2, 0.095144610420514142),\n",
       " (5, 0.27145301884279049),\n",
       " (8, 0.22502994302259652),\n",
       " (9, 0.35400241682931877)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get topic distribution\n",
    "lda[dictionary.doc2bow(test_doc_content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 5, 8, 9}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get set of topics\n",
    "test_doc_topics = {topic for topic,prob in lda[dictionary.doc2bow(test_doc_content)]}\n",
    "test_doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0.050514317571294882,\n",
       " 2: 0.095143317982485001,\n",
       " 3: 0,\n",
       " 4: 0,\n",
       " 5: 0.2714529385906066,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 0.22501907893871126,\n",
       " 9: 0.35400231751729327}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get LDA topic dictionary\n",
    "test_LDA_topics = dict()\n",
    "\n",
    "for i in range(10):\n",
    "    if i in test_doc_topics:\n",
    "        test_LDA_topics[i] = [prob \n",
    "                              for topic,prob \n",
    "                              in lda[dictionary.doc2bow(test_doc_content)]\n",
    "                              if topic == i][0]\n",
    "    else:\n",
    "        test_LDA_topics[i] = 0\n",
    "        \n",
    "test_LDA_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0.050509546326685383,\n",
       " 2: 0.095137970142599934,\n",
       " 3: 0,\n",
       " 4: 0,\n",
       " 5: 0.27145370838496719,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 0.22501073517084158,\n",
       " 9: 0.35400004898534237}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get LDA topic dictionary\n",
    "test_LDA_topics = dict()\n",
    "\n",
    "for i in range(10):\n",
    "    if i in test_doc_topics: \n",
    "        for topic,prob in lda[dictionary.doc2bow(test_doc_content)]:\n",
    "            if topic == i:\n",
    "                test_LDA_topics[i] = prob\n",
    "    else:\n",
    "        test_LDA_topics[i] = 0\n",
    "        \n",
    "test_LDA_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lda_features(doc):\n",
    "    \n",
    "    \"\"\"\n",
    "    Pull document from MongoDB collection of Mashable Articles \n",
    "    and generate LDA topic probabilities.\n",
    "    \n",
    "    Arguments:\n",
    "    Doc -- MongoDB Document\n",
    "    \n",
    "    Output:\n",
    "    Stores LDA topic probability results in Mongo DB for Document\n",
    "    \"\"\"\n",
    "    \n",
    "    # pull content from Mongo Doc\n",
    "    content = doc['content'].encode('utf8')\n",
    "    \n",
    "    # remove punctuation\n",
    "    content = \"\".join(char for char \n",
    "                      in content \n",
    "                      if char \n",
    "                      not in string.punctuation)\n",
    "    \n",
    "    # remove stopwords and tokenize\n",
    "    content = [word.decode('utf-8')\n",
    "               for word in content.lower().split() \n",
    "               if word.decode('utf-8') not in stop]\n",
    "    \n",
    "    # lemmatize vocabularly\n",
    "    content = [lmtzr.lemmatize(token) \n",
    "               for token in content]\n",
    "    \n",
    "    # get LDA features for Model\n",
    "    topic_probs = lda[dictionary.doc2bow(content)]\n",
    "    topics = {}\n",
    "    topics = {topic for (topic,prob) in topic_probs}\n",
    "    LDA_topics = dict()\n",
    "    for i in range(10):\n",
    "        if i in topics: \n",
    "            for (topic,prob) in topic_probs:\n",
    "                if topic == i:\n",
    "                    LDA_topics[i] = prob\n",
    "        else:\n",
    "            LDA_topics[i] = 0\n",
    "    \n",
    "    collection.update_one({\"_id\": doc[\"_id\"]}, \n",
    "                          {\"$set\": {\"LDA_0_prob\": LDA_topics[0], \n",
    "                                    \"LDA_1_prob\": LDA_topics[1],\n",
    "                                    \"LDA_2_prob\": LDA_topics[2], \n",
    "                                    \"LDA_3_prob\": LDA_topics[3], \n",
    "                                    \"LDA_4_prob\": LDA_topics[4],\n",
    "                                    \"LDA_5_prob\": LDA_topics[5], \n",
    "                                    \"LDA_6_prob\": LDA_topics[6],\n",
    "                                    \"LDA_7_prob\": LDA_topics[7],\n",
    "                                    \"LDA_8_prob\": LDA_topics[8],\n",
    "                                    \"LDA_9_prob\": LDA_topics[9]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n",
      "37000\n",
      "37100\n",
      "37200\n",
      "37300\n",
      "37400\n",
      "37500\n",
      "37600\n",
      "37700\n",
      "37800\n",
      "37900\n",
      "38000\n",
      "38100\n",
      "38200\n",
      "38300\n",
      "38400\n",
      "38500\n",
      "38600\n",
      "38700\n",
      "38800\n",
      "38900\n",
      "39000\n",
      "39100\n",
      "39200\n",
      "39300\n",
      "39400\n",
      "39500\n",
      "39600\n",
      "39700\n",
      "39800\n",
      "39900\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# get LDA features for all Mongo docs\n",
    "\n",
    "progress_counter = 0 \n",
    "\n",
    "for doc in collection.find({}, {\"content\": 1}):\n",
    "\n",
    "    get_lda_features(doc)\n",
    "\n",
    "    # show progress\n",
    "    progress_counter += 1\n",
    "    if progress_counter %100 == 0:\n",
    "        print progress_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
